{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80fee3f0",
   "metadata": {},
   "source": [
    "# HARLF v3: Data Collection\n",
    "\n",
    "Simple data collection pipeline for NLP features.\n",
    "\n",
    "**Steps:**\n",
    "1. Setup & imports\n",
    "2. Collect price data \n",
    "3. Calculate technical indicators\n",
    "4. Create NLP features\n",
    "5. Visualize & export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46eea8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ready for data collection\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "print(\"✅ Ready for data collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210c7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "PORTFOLIO_FILE = \"../data/portfolio_holdings.csv\"  # Fixed path\n",
    "PERIOD = \"20y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6d0bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection at 2025-08-07 11:31:53\n",
      " Portfolio loaded successfully with 18 unique tickers\n",
      "Tickers: ['RDDT', 'NVDA', 'SMR', 'MU', 'MRVL', 'MSFT', 'ASML', 'AEM', 'AMD', 'VERU', 'AI', 'GOOGL', 'INGM', 'PLUG', 'IONQ', 'CHYM', 'RGTI', 'ARBE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  18 of 18 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data download completed. Shape: (5031, 18)\n",
      "Date range: 2005-08-08 to 2025-08-06\n",
      "Number of trading days: 5031\n",
      "\n",
      " Dataset Summary:\n",
      "Features shape: (90558, 12)\n",
      "\n",
      " Date range: 2005-08-08 to 2025-08-06\n",
      "Price data shape: (5031, 18)\n",
      "\n",
      " Date range: 2005-08-08 to 2025-08-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def collect_numerical_data(portfolio_file=PORTFOLIO_FILE, period=PERIOD):\n",
    "\n",
    "    print(f\"Starting data collection at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    portfolio = pd.read_csv(portfolio_file)\n",
    "    tickers = portfolio['Ticker'].unique().tolist()\n",
    "\n",
    "    print(f\" Portfolio loaded successfully with {len(tickers)} unique tickers\")\n",
    "    print(f\"Tickers: {tickers}\")\n",
    " \n",
    "    PERIOD = period\n",
    "    data = yf.download(tickers, period=PERIOD, auto_adjust=True)['Close'].round(2)\n",
    "\n",
    "    print(f\" Data download completed. Shape: {data.shape}\")\n",
    "    print(f\"Date range: {data.index.min().strftime('%Y-%m-%d')} to {data.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Number of trading days: {len(data)}\")\n",
    "    \n",
    "    log_returns = np.log(data / data.shift(1)).fillna(0)\n",
    "    \n",
    "    sma10 = data.rolling(10).mean() / data - 1 # 10-day SMA\n",
    "    sma30 = data.rolling(30).mean() / data - 1 # 30-day SMA\n",
    "    \n",
    "    # Calculate volatility (10-day rolling standard deviation of returns)\n",
    "    volatility_10 = log_returns.rolling(10).std().fillna(0)\n",
    "    \n",
    "    # Calculate 60-day rolling statistics\n",
    "    log_return_mean_60 = log_returns.rolling(60).mean()\n",
    "    log_return_std_60 = log_returns.rolling(60).std()\n",
    "    # Sharpe ratio = mean return / standard deviation (with small epsilon to avoid division by zero)\n",
    "    sharpe_60 = log_return_mean_60 / (log_return_std_60 + 1e-8)\n",
    "    \n",
    "    # Calculate 120-day rolling statistics\n",
    "    log_return_mean_120 = log_returns.rolling(120).mean()\n",
    "    log_return_std_120 = log_returns.rolling(120).std()\n",
    "    sharpe_120 = log_return_mean_120 / (log_return_std_120 + 1e-8)\n",
    "    \n",
    "    # 5. Create Feature Dataset for Machine Learning (exactly as in notebook)\n",
    "\n",
    "    print(f\"\\n Dataset Summary:\")\n",
    "    \n",
    "    # Stack features into a single DataFrame in long form for ML/RL\n",
    "    feature_frames = []\n",
    "    \n",
    "    for ticker in data:\n",
    "        df = pd.DataFrame({\n",
    "            'Date': log_returns.index,\n",
    "            'Ticker': ticker,\n",
    "            'log_return': log_returns[ticker].values,\n",
    "            'sma10': sma10[ticker].values,\n",
    "            'sma30': sma30[ticker].values,\n",
    "            'volatility_10': volatility_10[ticker].values,\n",
    "            'log_return_mean_60': log_return_mean_60[ticker].values,\n",
    "            'log_return_std_60': log_return_std_60[ticker].values,\n",
    "            'sharpe_60': sharpe_60[ticker].values,\n",
    "            'log_return_mean_120': log_return_mean_120[ticker].values,\n",
    "            'log_return_std_120': log_return_std_120[ticker].values,\n",
    "            'sharpe_120': sharpe_120[ticker].values\n",
    "        })\n",
    "        feature_frames.append(df.round(4))\n",
    "    \n",
    "    # Combine all feature frames\n",
    "    features_df = pd.concat(feature_frames, ignore_index=True)\n",
    "    features_df.fillna(0, inplace=True)\n",
    "    \n",
    "    print(f\"Features shape: {features_df.shape}\")\n",
    "    print(f\"\\n Date range: {features_df.Date.min().strftime('%Y-%m-%d')} to {features_df.Date.max().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # 6. Prepare price data (exactly as in notebook)\n",
    "    prices = data.copy()\n",
    "    prices.fillna(0, inplace=True)\n",
    "    print(f\"Price data shape: {prices.shape}\")\n",
    "    print(f\"\\n Date range: {prices.index.min().strftime('%Y-%m-%d')} to {prices.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    return features_df, prices, log_returns, tickers\n",
    "\n",
    "features_df, prices, log_returns, tickers = collect_numerical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58e181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data collection completed successfully at 2025-08-07 11:33:23\n"
     ]
    }
   ],
   "source": [
    "# Save features and prices for training\n",
    "features_df.to_csv(\"../data/features_df_for_training.csv\", index=False)\n",
    "\n",
    "prices.to_csv(\"../data/price_data_for_training.csv\", index=True)\n",
    "\n",
    "# Save log returns data for sentiment analysis validation\n",
    "log_returns.to_csv(\"../data/log_returns_data.csv\", index=True)\n",
    "\n",
    "# Save list of tickers used for RL\n",
    "with open('rl_tickers.txt', 'w') as f:\n",
    "    for ticker in tickers:\n",
    "        f.write(f\"{ticker}\\n\")\n",
    "\n",
    "\n",
    "print(f\"\\n Data collection completed successfully at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demand_forecast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
