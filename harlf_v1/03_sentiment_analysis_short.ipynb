{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Sentiment Analysis Pipeline (One-Cell Version)\n",
    "\n",
    "This notebook is the streamlined replacement for the original 3k-line plan. It calls helper functions from `sentiment_utils.py`, keeping the notebook easy to read, debug, and rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_utils import (\n",
    "    collect_yahoo_news,\n",
    "    collect_google_news_monthly,\n",
    "    collect_reddit_sentiment,\n",
    "    load_finbert_pipeline,\n",
    "    analyze_sentiment_finbert_enhanced,\n",
    "    aggregate_monthly_sentiment_enhanced,\n",
    "    validate_sentiment_vs_returns,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Portfolio tickers\n",
    "# ------------------------------------------------------------------\n",
    "portfolio_assets = {\n",
    "    'RDDT': 'Reddit Inc',\n",
    "    'NVDA': 'NVIDIA Corporation',\n",
    "    'SMR': 'NuScale Power Corporation',\n",
    "    'MU': 'Micron Technology Inc',\n",
    "    'MRVL': 'Marvell Technology Group',\n",
    "    'MSFT': 'Microsoft Corporation',\n",
    "    'ASML': 'ASML Holding NV',\n",
    "    'AEM': 'Agnico Eagle Mines Ltd',\n",
    "    'AMD': 'Advanced Micro Devices',\n",
    "    'VERU': 'Veru Inc',\n",
    "    'AI': 'C3.ai Inc',\n",
    "    'GOOGL': 'Alphabet Inc (Google)',\n",
    "    'INGM': 'Inogen Inc',\n",
    "    'PLUG': 'Plug Power Inc',\n",
    "    'IONQ': 'IonQ Inc',\n",
    "    'CHYM': 'Anterix Inc',\n",
    "    'RGTI': 'Rigetti Computing Inc',\n",
    "    'ARBE': 'Arbe Robotics Ltd',\n",
    "}\n",
    "tickers = list(portfolio_assets.keys())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1  Load FinBERT\n",
    "# ------------------------------------------------------------------\n",
    "finbert = load_finbert_pipeline()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2  Collect news (Yahoo + Google + Reddit) with caching\n",
    "# ------------------------------------------------------------------\n",
    "yahoo_df  = collect_yahoo_news(tickers, portfolio_assets, start_year=2024)\n",
    "google_df = collect_google_news_monthly(tickers, portfolio_assets, start_year=2020, news_per_month=20)\n",
    "reddit_df = collect_reddit_sentiment(tickers, portfolio_assets, finbert, start_year=2020, posts_per_ticker=100)\n",
    "\n",
    "all_news = pd.concat([yahoo_df, google_df, reddit_df], ignore_index=True)\n",
    "print(f'Articles collected: {len(all_news):,}')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3  Sentiment inference & aggregation\n",
    "# ------------------------------------------------------------------\n",
    "sentiment_df = analyze_sentiment_finbert_enhanced(all_news, finbert)\n",
    "monthly_df   = aggregate_monthly_sentiment_enhanced(sentiment_df)\n",
    "\n",
    "# Save for downstream RL notebooks\n",
    "Path('outputs').mkdir(exist_ok=True)\n",
    "monthly_df.to_csv('outputs/enhanced_monthly_sentiment.csv', index=False)\n",
    "print('✓ Monthly sentiment saved → outputs/enhanced_monthly_sentiment.csv')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4  Validate vs log-returns (optional)\n",
    "# ------------------------------------------------------------------\n",
    "summary, _ = validate_sentiment_vs_returns(monthly_df, 'outputs/log_returns_data.csv')\n",
    "summary.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}