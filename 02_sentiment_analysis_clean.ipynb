{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732b78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries and Setup\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sentiment_utils import *\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fcf3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio assets loaded: 18 tickers\n",
      "Assets: ['RDDT', 'NVDA', 'SMR', 'MU', 'MRVL', 'MSFT', 'ASML', 'AEM', 'AMD', 'VERU', 'AI', 'GOOGL', 'INGM', 'PLUG', 'IONQ', 'CHYM', 'RGTI', 'ARBE']...\n",
      "Cache directory ready: news_cache\n",
      "Outputs directory ready: outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "portfolio_assets = {\n",
    "    'RDDT': 'Reddit Inc',\n",
    "    'NVDA': 'NVIDIA Corporation', \n",
    "    'SMR': 'NuScale Power Corporation',\n",
    "    'MU': 'Micron Technology Inc',\n",
    "    'MRVL': 'Marvell Technology Group',\n",
    "    'MSFT': 'Microsoft Corporation',\n",
    "    'ASML': 'ASML Holding NV',\n",
    "    'AEM': 'Agnico Eagle Mines Ltd',\n",
    "    'AMD': 'Advanced Micro Devices',\n",
    "    'VERU': 'Veru Inc',\n",
    "    'AI': 'C3.ai Inc',\n",
    "    'GOOGL': 'Alphabet Inc (Google)',\n",
    "    'INGM': 'Inogen Inc',\n",
    "    'PLUG': 'Plug Power Inc',\n",
    "    'IONQ': 'IonQ Inc',\n",
    "    'CHYM': 'Anterix Inc',\n",
    "    'RGTI': 'Rigetti Computing Inc',\n",
    "    'ARBE': 'Arbe Robotics Ltd'\n",
    "}\n",
    "\n",
    "tickers = list(portfolio_assets.keys())\n",
    "print(f\"Portfolio assets loaded: {len(tickers)} tickers\")\n",
    "print(f\"Assets: {list(portfolio_assets.keys())}...\")\n",
    "\n",
    "# Create directories for organized output\n",
    "cache_dir = Path(\"news_cache\")\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Cache directory ready: {cache_dir}\")\n",
    "print(f\"Outputs directory ready: {outputs_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3db96e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FinBERT model for financial sentiment analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FinBERT model loaded successfully\n",
      "Test sentiment: positive (confidence: 0.954)\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize FinBERT Model\n",
    "print(\"Loading FinBERT model for financial sentiment analysis...\")\n",
    "\n",
    "# Use FinBERT as specified in your plan\n",
    "finbert_pipeline = load_finbert_pipeline()\n",
    "print(\"✓ FinBERT model loaded successfully\")\n",
    "\n",
    "# Test the model\n",
    "test_text = \"NVIDIA reports strong quarterly earnings beating expectations\"\n",
    "test_result = finbert_pipeline(test_text)[0]\n",
    "print(f\"Test sentiment: {test_result['label']} (confidence: {test_result['score']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4118f0",
   "metadata": {},
   "source": [
    "## **Monthly Loop Strategy**\n",
    "\n",
    "**Why Follow Your Original Monthly Approach?**\n",
    "\n",
    "Your monthly loop logic, while computationally intensive, has several advantages:\n",
    "1. **Granular Control**: Each month can be individually validated and debugged\n",
    "2. **Temporal Precision**: Exact monthly boundaries for consistent aggregation\n",
    "3. **Error Isolation**: If one month fails, others continue processing\n",
    "4. **Data Quality**: More precise date filtering than quarterly batches\n",
    "\n",
    "**Optimization Balance**: We maintain your proven logic but add:\n",
    "- Smart caching to eliminate redundant API calls\n",
    "- Future month skipping to avoid unnecessary processing  \n",
    "- Better error handling to prevent cascade failures\n",
    "\n",
    "**Trade-off Analysis**: Monthly loops = more API calls but better data quality. With caching, we get the best of both worlds - precision on first run, speed on subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956dbef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Yahoo Finance news collection...\n",
      "Yahoo collection completed: 180 articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>headline</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>Reddit Inc</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Reddit, Coinbase, Novo Nordisk - Trending Stoc...</td>\n",
       "      <td>Reddit, Coinbase, Novo Nordisk - Trending Stocks</td>\n",
       "      <td>A quick look at some of the mornings most acti...</td>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>Reddit Inc</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>2025-07</td>\n",
       "      <td>Norwegian Cruise Line pops, Lam Research slips...</td>\n",
       "      <td>Norwegian Cruise Line pops, Lam Research slips...</td>\n",
       "      <td>Here are some of the stories Wall Street is wa...</td>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker     company        date    month  \\\n",
       "0   RDDT  Reddit Inc  2025-08-01  2025-08   \n",
       "1   RDDT  Reddit Inc  2025-07-31  2025-07   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Reddit, Coinbase, Novo Nordisk - Trending Stoc...   \n",
       "1  Norwegian Cruise Line pops, Lam Research slips...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Reddit, Coinbase, Novo Nordisk - Trending Stocks   \n",
       "1  Norwegian Cruise Line pops, Lam Research slips...   \n",
       "\n",
       "                                             summary source  \n",
       "0  A quick look at some of the mornings most acti...  yahoo  \n",
       "1  Here are some of the stories Wall Street is wa...  yahoo  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect Yahoo Finance news\n",
    "print(\"Starting Yahoo Finance news collection...\")\n",
    "yahoo_news_df = collect_yahoo_news(tickers, portfolio_assets, start_year=2024, end_year=None)  # Test with 2 assets\n",
    "print(f\"Yahoo collection completed: {len(yahoo_news_df)} articles\")\n",
    "yahoo_news_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7526a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Google News collection with quality filtering...\n",
      "Google collection completed: 10678 articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>headline</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>Reddit Inc</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>Here’s Why Shaftesbury Share Price Crashed 18%...</td>\n",
       "      <td>Here’s Why Shaftesbury Share Price Crashed 18%...</td>\n",
       "      <td>Here’s Why Shaftesbury Share Price Crashed 18%...</td>\n",
       "      <td>google</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>Reddit Inc</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>2021-05</td>\n",
       "      <td>Top 10 Stock Picks of Barry Ritholtz and Josh ...</td>\n",
       "      <td>Top 10 Stock Picks of Barry Ritholtz and Josh ...</td>\n",
       "      <td>Top 10 Stock Picks of Barry Ritholtz and Josh ...</td>\n",
       "      <td>google</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker     company        date    month  \\\n",
       "0   RDDT  Reddit Inc  2020-10-22  2020-10   \n",
       "1   RDDT  Reddit Inc  2021-05-26  2021-05   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Here’s Why Shaftesbury Share Price Crashed 18%...   \n",
       "1  Top 10 Stock Picks of Barry Ritholtz and Josh ...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Here’s Why Shaftesbury Share Price Crashed 18%...   \n",
       "1  Top 10 Stock Picks of Barry Ritholtz and Josh ...   \n",
       "\n",
       "                                         description  source link Date Ticker  \\\n",
       "0  Here’s Why Shaftesbury Share Price Crashed 18%...  google       NaN    NaN   \n",
       "1  Top 10 Stock Picks of Barry Ritholtz and Josh ...  google       NaN    NaN   \n",
       "\n",
       "  desc  \n",
       "0  NaN  \n",
       "1  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect Google News following your monthly approach with quality filtering\n",
    "print(\"\\nStarting Google News collection with quality filtering...\")\n",
    "google_news_df = collect_google_news_monthly(tickers, portfolio_assets, start_year=2020, end_year=None, news_per_month=20)\n",
    "print(f\"Google collection completed: {len(google_news_df)} articles\")\n",
    "google_news_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e19130a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Reddit sentiment data...\n",
      "Reddit collection completed: 553 articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>headline</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>Reddit Inc</td>\n",
       "      <td>2025-01-29</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>Reflections on a career in security selection ...</td>\n",
       "      <td>Reflections on a career in security selection ...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>SecurityAnalysis</td>\n",
       "      <td>58</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.908983</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>Reddit Inc</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2025 Analysis Questions and Discussions Thread...</td>\n",
       "      <td>2025 Analysis Questions and Discussions Thread</td>\n",
       "      <td>reddit</td>\n",
       "      <td>SecurityAnalysis</td>\n",
       "      <td>18</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.937423</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker     company        date    month  \\\n",
       "0   RDDT  Reddit Inc  2025-01-29  2025-01   \n",
       "1   RDDT  Reddit Inc  2025-01-16  2025-01   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Reflections on a career in security selection ...   \n",
       "1  2025 Analysis Questions and Discussions Thread...   \n",
       "\n",
       "                                               title  source  \\\n",
       "0  Reflections on a career in security selection ...  reddit   \n",
       "1     2025 Analysis Questions and Discussions Thread  reddit   \n",
       "\n",
       "          subreddit  reddit_score sentiment_label  sentiment_confidence  \\\n",
       "0  SecurityAnalysis            58         neutral              0.908983   \n",
       "1  SecurityAnalysis            18         neutral              0.937423   \n",
       "\n",
       "   sentiment_score  \n",
       "0              0.0  \n",
       "1              0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Collecting Reddit sentiment data...\")\n",
    "# Changed posts_per_month to posts_per_ticker to match the new parameter name\n",
    "reddit_news_df = collect_reddit_sentiment(tickers, portfolio_assets, finbert_pipeline, start_year=2020, end_year=None, posts_per_ticker=100)\n",
    "print(f\"Reddit collection completed: {len(reddit_news_df)} articles\")\n",
    "reddit_news_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a064b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined sources: Yahoo Finance + Google News + Reddit\n",
      "\n",
      " Combined News Data Summary:\n",
      "Total articles: 11411\n",
      "Date range: 2020-01-02 to 2025-08-01\n",
      "Assets covered: 18\n",
      "\n",
      "Source breakdown:\n",
      "  google: 10678 articles (93.6%)\n",
      "  reddit: 553 articles (4.8%)\n",
      "  yahoo: 180 articles (1.6%)\n",
      "\n",
      "Monthly coverage: 1078 month-asset-source combinations\n",
      "\n",
      "Sample combined data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>source</th>\n",
       "      <th>month</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Reddit, Coinbase, Novo Nordisk - Trending Stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-07</td>\n",
       "      <td>Norwegian Cruise Line pops, Lam Research slips...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Stocks Slump on Tariffs and Weak US Job Growth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Stocks to Watch Friday: Amazon, Coinbase, Redd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Stock Market Today: Dow Tumbles On New Trump T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>July Payrolls Miss Forecasts, Driving Premarke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>RDDT: Reddit Stock Soars After Q2 Revenue Smas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Dow Jones Futures Fall On Global Trump Tariff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Reddit plans to unify its search interface as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RDDT</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>Trending tickers: Figma, Apple, Amazon, Reddit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker source    month                                           headline\n",
       "0   RDDT  yahoo  2025-08  Reddit, Coinbase, Novo Nordisk - Trending Stoc...\n",
       "1   RDDT  yahoo  2025-07  Norwegian Cruise Line pops, Lam Research slips...\n",
       "2   RDDT  yahoo  2025-08  Stocks Slump on Tariffs and Weak US Job Growth...\n",
       "3   RDDT  yahoo  2025-08  Stocks to Watch Friday: Amazon, Coinbase, Redd...\n",
       "4   RDDT  yahoo  2025-08  Stock Market Today: Dow Tumbles On New Trump T...\n",
       "5   RDDT  yahoo  2025-08  July Payrolls Miss Forecasts, Driving Premarke...\n",
       "6   RDDT  yahoo  2025-08  RDDT: Reddit Stock Soars After Q2 Revenue Smas...\n",
       "7   RDDT  yahoo  2025-08  Dow Jones Futures Fall On Global Trump Tariff ...\n",
       "8   RDDT  yahoo  2025-08  Reddit plans to unify its search interface as ...\n",
       "9   RDDT  yahoo  2025-08  Trending tickers: Figma, Apple, Amazon, Reddit..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Combine All News Sources & Data Quality Check\n",
    "\n",
    "# Combine all three sources\n",
    "all_news_df = pd.concat([yahoo_news_df, google_news_df, reddit_news_df], ignore_index=True)\n",
    "print(f\"Combined sources: Yahoo Finance + Google News + Reddit\")\n",
    "\n",
    "print(f\"\\n Combined News Data Summary:\")\n",
    "print(f\"Total articles: {len(all_news_df)}\")\n",
    "print(f\"Date range: {all_news_df['date'].min()} to {all_news_df['date'].max()}\")\n",
    "print(f\"Assets covered: {all_news_df['ticker'].nunique()}\")\n",
    "\n",
    "# Source breakdown\n",
    "source_breakdown = all_news_df['source'].value_counts()\n",
    "print(f\"\\nSource breakdown:\")\n",
    "for source, count in source_breakdown.items():\n",
    "    print(f\"  {source}: {count} articles ({count/len(all_news_df)*100:.1f}%)\")\n",
    "\n",
    "# Monthly coverage\n",
    "monthly_coverage = all_news_df.groupby(['ticker', 'month', 'source']).size().reset_index(name='count')\n",
    "print(f\"\\nMonthly coverage: {len(monthly_coverage)} month-asset-source combinations\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nSample combined data:\")\n",
    "all_news_df[['ticker', 'source', 'month', 'headline']].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27de72c",
   "metadata": {},
   "source": [
    "## **Reflection: Source Weighting and Aggregation**\n",
    "\n",
    "**The Challenge of Multi-Source Integration**\n",
    "\n",
    "Combining sentiment from different sources requires careful consideration:\n",
    "\n",
    "**Equal Weighting Approach**: Our current method treats Yahoo Finance and Google News equally. This is a reasonable starting point but could be enhanced.\n",
    "\n",
    "**Potential Improvements**:\n",
    "- **Volume-based weighting**: Weight by number of articles (more data = more confidence)\n",
    "- **Recency weighting**: Recent news should have higher impact\n",
    "- **Source credibility**: Financial publications might deserve higher weights\n",
    "- **Asset-specific weighting**: Some assets might have better coverage in certain sources\n",
    "\n",
    "**Aggregation Formula**: We follow your plan's formula: `Sentiment Score = (1/N) * Σ(P+ - P-)` which provides a clean [-1, +1] range suitable for RL features.\n",
    "\n",
    "**Statistical Considerations**: By tracking both mean and standard deviation, we capture not just sentiment direction but also consensus level - high std indicates mixed sentiment, which itself is valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ee2ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>headline</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>desc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11406</th>\n",
       "      <td>ARBE</td>\n",
       "      <td>Arbe Robotics Ltd</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>2024-11</td>\n",
       "      <td>ARBB IOT &amp; ASTERA LABS Couple rockets that it ...</td>\n",
       "      <td>ARBB IOT &amp; ASTERA LABS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>11.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.823303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11407</th>\n",
       "      <td>ARBE</td>\n",
       "      <td>Arbe Robotics Ltd</td>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>2024-11</td>\n",
       "      <td>Thoughts on streaming landscape? Thought I’d p...</td>\n",
       "      <td>Thoughts on streaming landscape?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.516304</td>\n",
       "      <td>0.516304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11408</th>\n",
       "      <td>ARBE</td>\n",
       "      <td>Arbe Robotics Ltd</td>\n",
       "      <td>2024-09-17</td>\n",
       "      <td>2024-09</td>\n",
       "      <td>Corporate bond reserarch? For those who do any...</td>\n",
       "      <td>Corporate bond reserarch?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.925296</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11409</th>\n",
       "      <td>ARBE</td>\n",
       "      <td>Arbe Robotics Ltd</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>$SGRP merger - shares selling at a discount In...</td>\n",
       "      <td>$SGRP merger - shares selling at a discount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>investing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.832358</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11410</th>\n",
       "      <td>ARBE</td>\n",
       "      <td>Arbe Robotics Ltd</td>\n",
       "      <td>2024-08-17</td>\n",
       "      <td>2024-08</td>\n",
       "      <td>Question about $COF acquisition of $DSF I’ve b...</td>\n",
       "      <td>Question about $COF acquisition of $DSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.912530</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker            company        date    month  \\\n",
       "11406   ARBE  Arbe Robotics Ltd  2024-11-06  2024-11   \n",
       "11407   ARBE  Arbe Robotics Ltd  2024-11-29  2024-11   \n",
       "11408   ARBE  Arbe Robotics Ltd  2024-09-17  2024-09   \n",
       "11409   ARBE  Arbe Robotics Ltd  2024-12-05  2024-12   \n",
       "11410   ARBE  Arbe Robotics Ltd  2024-08-17  2024-08   \n",
       "\n",
       "                                                headline  \\\n",
       "11406  ARBB IOT & ASTERA LABS Couple rockets that it ...   \n",
       "11407  Thoughts on streaming landscape? Thought I’d p...   \n",
       "11408  Corporate bond reserarch? For those who do any...   \n",
       "11409  $SGRP merger - shares selling at a discount In...   \n",
       "11410  Question about $COF acquisition of $DSF I’ve b...   \n",
       "\n",
       "                                             title summary  source  \\\n",
       "11406                       ARBB IOT & ASTERA LABS     NaN  reddit   \n",
       "11407             Thoughts on streaming landscape?     NaN  reddit   \n",
       "11408                    Corporate bond reserarch?     NaN  reddit   \n",
       "11409  $SGRP merger - shares selling at a discount     NaN  reddit   \n",
       "11410      Question about $COF acquisition of $DSF     NaN  reddit   \n",
       "\n",
       "      description link Date Ticker desc       subreddit  reddit_score  \\\n",
       "11406         NaN  NaN  NaN    NaN  NaN  wallstreetbets          11.0   \n",
       "11407         NaN  NaN  NaN    NaN  NaN  ValueInvesting           5.0   \n",
       "11408         NaN  NaN  NaN    NaN  NaN  wallstreetbets           5.0   \n",
       "11409         NaN  NaN  NaN    NaN  NaN       investing           2.0   \n",
       "11410         NaN  NaN  NaN    NaN  NaN  ValueInvesting           2.0   \n",
       "\n",
       "      sentiment_label  sentiment_confidence  sentiment_score  \n",
       "11406         neutral              0.823303         0.000000  \n",
       "11407        positive              0.516304         0.516304  \n",
       "11408         neutral              0.925296         0.000000  \n",
       "11409         neutral              0.832358         0.000000  \n",
       "11410         neutral              0.912530         0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = analyze_sentiment_finbert_enhanced(all_news_df, finbert_pipeline)\n",
    "sentiment_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1511ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Monthly sentiment saved → outputs/enhanced_monthly_sentiment.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment_mean</th>\n",
       "      <th>sentiment_std</th>\n",
       "      <th>news_count</th>\n",
       "      <th>confidence_mean</th>\n",
       "      <th>company</th>\n",
       "      <th>google_news_count</th>\n",
       "      <th>reddit_news_count</th>\n",
       "      <th>yahoo_news_count</th>\n",
       "      <th>google_sentiment_mean</th>\n",
       "      <th>reddit_sentiment_mean</th>\n",
       "      <th>yahoo_sentiment_mean</th>\n",
       "      <th>sentiment_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEM</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576321</td>\n",
       "      <td>Agnico Eagle Mines Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEM</td>\n",
       "      <td>2020-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932869</td>\n",
       "      <td>Agnico Eagle Mines Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEM</td>\n",
       "      <td>2020-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.644070</td>\n",
       "      <td>Agnico Eagle Mines Ltd</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.930615</td>\n",
       "      <td>Agnico Eagle Mines Ltd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.465859</td>\n",
       "      <td>2</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>Agnico Eagle Mines Ltd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    month  sentiment_mean  sentiment_std  news_count  confidence_mean  \\\n",
       "0    AEM  2020-01        0.000000       0.000000           1         0.576321   \n",
       "1    AEM  2020-02        0.000000       0.000000           1         0.932869   \n",
       "2    AEM  2020-03        0.000000       0.000000           3         0.644070   \n",
       "3    AEM  2020-04        0.000000       0.000000           2         0.930615   \n",
       "4    AEM  2020-05        0.329412       0.465859           2         0.799754   \n",
       "\n",
       "                  company  google_news_count  reddit_news_count  \\\n",
       "0  Agnico Eagle Mines Ltd                1.0                0.0   \n",
       "1  Agnico Eagle Mines Ltd                1.0                0.0   \n",
       "2  Agnico Eagle Mines Ltd                3.0                0.0   \n",
       "3  Agnico Eagle Mines Ltd                2.0                0.0   \n",
       "4  Agnico Eagle Mines Ltd                2.0                0.0   \n",
       "\n",
       "   yahoo_news_count  google_sentiment_mean  reddit_sentiment_mean  \\\n",
       "0               0.0               0.000000                    0.0   \n",
       "1               0.0               0.000000                    0.0   \n",
       "2               0.0               0.000000                    0.0   \n",
       "3               0.0               0.000000                    0.0   \n",
       "4               0.0               0.329412                    0.0   \n",
       "\n",
       "   yahoo_sentiment_mean  sentiment_weighted  \n",
       "0                   0.0            0.000000  \n",
       "1                   0.0            0.000000  \n",
       "2                   0.0            0.000000  \n",
       "3                   0.0            0.000000  \n",
       "4                   0.0            0.329412  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate monthly sentiment\n",
    "monthly_df = aggregate_monthly_sentiment_enhanced(sentiment_df)\n",
    "monthly_df.to_csv('outputs/enhanced_monthly_sentiment.csv', index=False)\n",
    "print('✓ Monthly sentiment saved → outputs/enhanced_monthly_sentiment.csv')\n",
    "monthly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3e668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Merged data saved → outputs/merged_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# validate vs log-returns\n",
    "returns_file_path = 'outputs/log_returns_data.csv'\n",
    "summary, merged_df = validate_sentiment_vs_returns(monthly_df, returns_file_path)\n",
    "summary.head()\n",
    "\n",
    "# save merged_df\n",
    "merged_df.to_csv('outputs/merged_df.csv', index=False)\n",
    "print('✓ Merged data saved → outputs/merged_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a71c5",
   "metadata": {},
   "source": [
    "## **Reflection: Validation Strategy**\n",
    "\n",
    "**Why Validate Sentiment Against Returns?**\n",
    "\n",
    "Sentiment analysis is only valuable if it correlates with actual market movements. Our validation approach:\n",
    "\n",
    "**Correlation Analysis**: We calculate Pearson correlation between monthly sentiment and monthly returns. This tells us:\n",
    "- **Signal Quality**: High correlation = sentiment has predictive power\n",
    "- **Asset-Specific Performance**: Some assets may have better sentiment-return relationships\n",
    "- **Time Lag Effects**: We can test lagged correlations (sentiment today → returns next month)\n",
    "\n",
    "**Expected Results**:\n",
    "- **Strong correlations (>0.3)**: Sentiment is a valuable RL feature\n",
    "- **Weak correlations (<0.1)**: May need different sentiment approach or longer time periods\n",
    "- **Negative correlations**: Could indicate contrarian signals (bad news = buying opportunity)\n",
    "\n",
    "**RL Integration Impact**: Only validated sentiment signals should receive high weights in the RL feature space. This validation step prevents us from training on noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Enhanced Visualization with Source Comparison\n",
    "\n",
    "# Create comprehensive visualizations (1x3 layout)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Source comparison (all available sources)\n",
    "sources = []\n",
    "avg_sentiments = []\n",
    "colors = []\n",
    "\n",
    "# Check and add each source\n",
    "if 'yahoo_sentiment_mean' in monthly_sentiment.columns:\n",
    "    sources.append('Yahoo Finance')\n",
    "    avg_sentiments.append(monthly_sentiment['yahoo_sentiment_mean'].mean())\n",
    "    colors.append('blue')\n",
    "    \n",
    "if 'google_sentiment_mean' in monthly_sentiment.columns:\n",
    "    sources.append('Google News')\n",
    "    avg_sentiments.append(monthly_sentiment['google_sentiment_mean'].mean())\n",
    "    colors.append('red')\n",
    "    \n",
    "if 'reddit_sentiment_mean' in monthly_sentiment.columns:\n",
    "    sources.append('Reddit')\n",
    "    avg_sentiments.append(monthly_sentiment['reddit_sentiment_mean'].mean())\n",
    "    colors.append('purple')\n",
    "\n",
    "if sources:\n",
    "    bars = ax1.bar(sources, avg_sentiments, color=colors, alpha=0.7)\n",
    "    ax1.set_title('Average Sentiment by Source')\n",
    "    ax1.set_ylabel('Average Sentiment Score')\n",
    "    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, avg_sentiments):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "else:\n",
    "    ax1.text(0.5, 0.5, 'Source comparison not available', \n",
    "            ha='center', va='center', transform=ax1.transAxes)\n",
    "    ax1.set_title('Source Comparison')\n",
    "\n",
    "# Plot 2: News coverage by source and asset\n",
    "if not all_news_df.empty:\n",
    "    coverage_data = all_news_df.groupby(['ticker', 'source']).size().unstack(fill_value=0)\n",
    "    coverage_data.plot(kind='bar', ax=ax2, alpha=0.7)\n",
    "    ax2.set_title('News Coverage by Asset and Source')\n",
    "    ax2.set_xlabel('Asset')\n",
    "    ax2.set_ylabel('Number of Articles')\n",
    "    ax2.legend(title='Source')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Sentiment distribution comparison\n",
    "ax3.hist(monthly_sentiment['sentiment_mean'], bins=15, alpha=0.7, \n",
    "            color='purple', label='Combined', density=True)\n",
    "ax3.set_title('Sentiment Score Distribution\\n(All Sources Combined)')\n",
    "ax3.set_xlabel('Sentiment Score')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax3.axvline(x=monthly_sentiment['sentiment_mean'].mean(), \n",
    "            color='red', linestyle='-', alpha=0.7, label=f'Mean: {monthly_sentiment[\"sentiment_mean\"].mean():.3f}')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEnhanced Sentiment Analysis Complete!\")\n",
    "print(f\"Triple sources: Yahoo Finance + Google News + Reddit\")\n",
    "print(f\"FinBERT professional sentiment analysis\")\n",
    "print(f\"Source-weighted monthly aggregation\")\n",
    "print(f\"Performance: Optimized vs original slow approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Visualization: Monthly Weighted Sentiment by Asset (Detailed View)\n",
    "\n",
    "# Fix chronological ordering of months\n",
    "monthly_sentiment_sorted = monthly_sentiment.copy()\n",
    "monthly_sentiment_sorted['month_date'] = pd.to_datetime(monthly_sentiment_sorted['month'] + '-01')\n",
    "monthly_sentiment_sorted = monthly_sentiment_sorted.sort_values(['ticker', 'month_date'])\n",
    "\n",
    "# Create a larger, more detailed version of the sentiment time series\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot sentiment over time by asset with proper chronological order\n",
    "for ticker in monthly_sentiment_sorted['ticker'].unique():\n",
    "    ticker_data = monthly_sentiment_sorted[monthly_sentiment_sorted['ticker'] == ticker]\n",
    "    plt.plot(ticker_data['month_date'], ticker_data['sentiment_weighted'], \n",
    "            marker='o', label=ticker, alpha=0.8, linewidth=3, markersize=8)\n",
    "\n",
    "plt.title('Monthly Weighted Sentiment by Asset\\n(Combined Yahoo Finance + Google News)', \n",
    "            fontsize=18, fontweight='bold', pad=20)\n",
    "plt.xlabel('Month', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Weighted Sentiment Score (P+ - P-)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Improve legend\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12, \n",
    "            title='Assets', title_fontsize=14)\n",
    "\n",
    "# Add horizontal line at zero\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "# Improve grid\n",
    "plt.grid(True, alpha=0.3, linewidth=1)\n",
    "\n",
    "# Rotate x-axis labels for better readability and format dates\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Format x-axis to show dates properly\n",
    "from matplotlib.dates import DateFormatter, YearLocator, MonthLocator\n",
    "plt.gca().xaxis.set_major_locator(YearLocator())\n",
    "plt.gca().xaxis.set_minor_locator(MonthLocator(interval=6))\n",
    "plt.gca().xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "\n",
    "# Add some statistical annotations\n",
    "overall_mean = monthly_sentiment_sorted['sentiment_weighted'].mean()\n",
    "plt.axhline(y=overall_mean, color='red', linestyle=':', alpha=0.7, linewidth=2, \n",
    "            label=f'Overall Mean: {overall_mean:.3f}')\n",
    "\n",
    "# Tight layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics for each asset\n",
    "print(\"\\nDetailed Sentiment Statistics by Asset:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "asset_stats = monthly_sentiment_sorted.groupby('ticker').agg({\n",
    "    'sentiment_weighted': ['mean', 'std', 'min', 'max', 'count'],\n",
    "    'news_count': 'sum'\n",
    "}).round(3)\n",
    "\n",
    "# Flatten column names\n",
    "asset_stats.columns = ['Sentiment_Mean', 'Sentiment_Std', 'Sentiment_Min', \n",
    "                        'Sentiment_Max', 'Months_Covered', 'Total_Articles']\n",
    "\n",
    "# Sort by sentiment mean for better analysis\n",
    "asset_stats = asset_stats.sort_values('Sentiment_Mean', ascending=False)\n",
    "\n",
    "display(asset_stats)\n",
    "\n",
    "# Identify most positive and negative assets\n",
    "most_positive = asset_stats.index[0]\n",
    "most_negative = asset_stats.index[-1]\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"Most Positive Asset: {most_positive} (avg: {asset_stats.loc[most_positive, 'Sentiment_Mean']:.3f})\")\n",
    "print(f\"Most Negative Asset: {most_negative} (avg: {asset_stats.loc[most_negative, 'Sentiment_Mean']:.3f})\")\n",
    "print(f\"Highest Volatility: {asset_stats['Sentiment_Std'].idxmax()} (std: {asset_stats['Sentiment_Std'].max():.3f})\")\n",
    "print(f\"Most Stable: {asset_stats['Sentiment_Std'].idxmin()} (std: {asset_stats['Sentiment_Std'].min():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Asset Sentiment Analysis (Focus on Top Performers)\n",
    "# Use the chronologically sorted data\n",
    "monthly_sentiment_sorted = monthly_sentiment.copy()\n",
    "monthly_sentiment_sorted['month_date'] = pd.to_datetime(monthly_sentiment_sorted['month'] + '-01')\n",
    "monthly_sentiment_sorted = monthly_sentiment_sorted.sort_values(['ticker', 'month_date'])\n",
    "\n",
    "# Create subplot for top 6 assets by sentiment\n",
    "asset_stats = monthly_sentiment_sorted.groupby('ticker')['sentiment_weighted'].mean().sort_values(ascending=False)\n",
    "top_assets = asset_stats.head(6).index\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ticker in enumerate(top_assets):\n",
    "    ticker_data = monthly_sentiment_sorted[monthly_sentiment_sorted['ticker'] == ticker]\n",
    "    \n",
    "    axes[i].plot(ticker_data['month_date'], ticker_data['sentiment_weighted'], \n",
    "                marker='o', linewidth=3, markersize=8, color=f'C{i}', alpha=0.8)\n",
    "    \n",
    "    axes[i].set_title(f'{ticker} - {portfolio_assets[ticker]}', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[i].set_ylabel('Sentiment Score', fontsize=12)\n",
    "    axes[i].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Format dates properly for individual plots\n",
    "    from matplotlib.dates import DateFormatter, YearLocator\n",
    "    axes[i].xaxis.set_major_locator(YearLocator())\n",
    "    axes[i].xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = ticker_data['sentiment_weighted'].mean()\n",
    "    axes[i].axhline(y=mean_val, color='red', linestyle=':', alpha=0.7,\n",
    "                    label=f'Mean: {mean_val:.3f}')\n",
    "    axes[i].legend(fontsize=10)\n",
    "\n",
    "plt.suptitle('Top 6 Assets by Average Sentiment Score', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table for all assets\n",
    "\n",
    "ranking_df = monthly_sentiment_sorted.groupby('ticker').agg({\n",
    "    'sentiment_weighted': 'mean',\n",
    "    'news_count': 'sum'\n",
    "}).round(3)\n",
    "\n",
    "ranking_df.columns = ['Avg_Sentiment', 'Total_Articles']\n",
    "ranking_df['Company'] = ranking_df.index.map(portfolio_assets)\n",
    "ranking_df = ranking_df.sort_values('Avg_Sentiment', ascending=False)\n",
    "ranking_df['Rank'] = range(1, len(ranking_df) + 1)\n",
    "\n",
    "# Reorder columns\n",
    "ranking_df = ranking_df[['Rank', 'Company', 'Avg_Sentiment', 'Total_Articles']]\n",
    "ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save Enhanced Results for RL Integration\n",
    "# Save enhanced monthly sentiment data\n",
    "monthly_sentiment.to_csv(outputs_dir / 'enhanced_monthly_sentiment.csv', index=False)\n",
    "print(\"✓ Enhanced monthly sentiment saved to 'outputs/enhanced_monthly_sentiment.csv'\")\n",
    "\n",
    "# Save detailed sentiment data with sources\n",
    "if not sentiment_df.empty:\n",
    "    sentiment_df.to_csv(outputs_dir / 'detailed_sentiment_with_sources.csv', index=False)\n",
    "    print(\"✓ Detailed sentiment with sources saved to 'outputs/detailed_sentiment_with_sources.csv'\")\n",
    "\n",
    "# Save combined news data\n",
    "if not all_news_df.empty:\n",
    "    all_news_df.to_csv(outputs_dir / 'combined_news_data.csv', index=False)\n",
    "    print(\"✓ Combined news data saved to 'outputs/combined_news_data.csv'\")\n",
    "\n",
    "# Show file sizes\n",
    "files = [\n",
    "    'enhanced_monthly_sentiment.csv',\n",
    "    'detailed_sentiment_with_sources.csv', \n",
    "    'combined_news_data.csv',\n",
    "]\n",
    "\n",
    "print(f\"\\nGenerated Files in outputs/ directory:\")\n",
    "for file in files:\n",
    "    file_path = outputs_dir / file\n",
    "    if file_path.exists():\n",
    "        size = file_path.stat().st_size / 1024  # KB\n",
    "        print(f\"  outputs/{file}: {size:.1f} KB\")\n",
    "\n",
    "print(f\"\\nEnhanced Data Ready for RL Integration:\")\n",
    "print(f\"- Monthly sentiment features: {len(monthly_sentiment)} records\")\n",
    "print(f\"- Source diversity: Yahoo Finance + Google News + Reddit\")\n",
    "print(f\"- Assets covered: {monthly_sentiment['ticker'].nunique()}\")\n",
    "print(f\"- Date range: {monthly_sentiment['month'].min()} to {monthly_sentiment['month'].max()}\")\n",
    "print(f\"- Average weighted sentiment: {monthly_sentiment['sentiment_weighted'].mean():.3f}\")\n",
    "print(f\"- All files saved to outputs/ directory for organized project structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e088b3",
   "metadata": {},
   "source": [
    "## **Reflection: Integration with HARLF Framework**\n",
    "\n",
    "**How Sentiment Enhances Hierarchical RL**\n",
    "\n",
    "This sentiment pipeline directly supports your HARLF plan:\n",
    "\n",
    "**Base Agent Level**: \n",
    "- **Sentiment-only agents**: Train RL agents using only sentiment features\n",
    "- **Price-only agents**: Traditional technical analysis agents  \n",
    "- **Comparison**: Isolate sentiment's contribution to performance\n",
    "\n",
    "**Meta-Agent Level**:\n",
    "- **Feature fusion**: Combine sentiment and price signals optimally\n",
    "- **Dynamic weighting**: Learn when sentiment matters most (earnings seasons, market volatility)\n",
    "- **Source arbitrage**: Exploit differences between institutional and retail sentiment\n",
    "\n",
    "**Super-Agent Level**:\n",
    "- **Multi-modal integration**: Sentiment becomes one of many signal types\n",
    "- **Regime detection**: Different market regimes may require different sentiment weights\n",
    "- **Risk management**: Sentiment divergence as a risk signal\n",
    "\n",
    "**Strategic Advantage**: Most quantitative strategies ignore sentiment. By incorporating professional-grade sentiment analysis, we gain an edge in markets increasingly driven by narrative and perception."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1323207f",
   "metadata": {},
   "source": [
    "## **Final Summary: Enhanced Sentiment Analysis Pipeline Complete**\n",
    "\n",
    "### **Files Generated (in outputs/ directory):**\n",
    "- `outputs/enhanced_monthly_sentiment.csv` - Monthly sentiment features for RL model\n",
    "- `outputs/detailed_sentiment_with_sources.csv` - Article-level sentiment analysis\n",
    "- `outputs/combined_news_data.csv` - Raw news data from both sources\n",
    "- `outputs/performance_comparison.json` - Performance metrics and improvements\n",
    "\n",
    "### **Key Achievements:**\n",
    "- **Data Quality**: FinBERT professional sentiment analysis\n",
    "- **Source Diversity**: Yahoo Finance + Google News integration\n",
    "- **RL Ready**: Clean monthly features for hierarchical RL training\n",
    "- **Organized**: All outputs saved to dedicated outputs/ directory\n",
    "\n",
    "### **Next Steps for HARLF Integration:**\n",
    "1. **Feature Integration**: Combine sentiment data with price features from `01_data_collection.ipynb`\n",
    "2. **Base Agent Training**: Train sentiment-only RL agents\n",
    "3. **Meta-Agent Development**: Fuse sentiment and price signals\n",
    "4. **Super-Agent**: Final hierarchical integration\n",
    "5. **Backtesting**: Validate performance with sentiment-enhanced strategies\n",
    "\n",
    "**The sentiment analysis pipeline is now complete and ready for integration with your hierarchical RL framework!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demand_forecast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
